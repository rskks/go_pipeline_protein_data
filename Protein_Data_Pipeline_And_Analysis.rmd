---
title: 'Pipeline: Filter Proteins by GO Term'
author: "Ronnie Yalung"
output:
  html_document: default
  pdf_document: default
---
# Package install. Only need to run once. May take a while
```{r}
install.packages("readxl")
install.packages("dplyr")
install.packages("tidyr")
install.packages("ggplot2")
install.packages("pheatmap")
install.packages("gprofiler2")
install.packages("httr")
install.packages("jsonlite")
install.packages("ggVennDiagram")
install.packages("Co")
```

# Document set up and library initialization. Run each different time opening the file.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
library(stringr)
library(httr)
library(jsonlite)
library(xml2)
library(purrr)
library(tibble)
library(tidyr)
library(furrr)
library(future)
library(progressr)
library(ggplot2)
library(ggVennDiagram)
library(plotly)
library(ComplexUpset)
```

### BEFORE EXECUTING ANY FURTHER CODE CELLS, FIRST LOAD THE FUNCTIONS FROM `pipeline_functions.rmd`, `filter_functions.rmd`, AND `data_analysis_functions.rmd` INTO R's GLOBAL ENV (EXECUTE THE CODE CELL(S) IN THE RESPECTIVE FILES).

# Read .xlsx file /Users/ronnie.yalung/Documents/work/samplestest.xlsx
```{r}
print("Note: File format HAS to be in .xlsx, as R can't read the raw .xls Scaffold data. To do this, open the .xls file in 
      Microsoft Excel, then Save As an Excel Workbook (.xlsx) in the File Format options.")

xlsx_path <- as.character(readline(prompt = "Enter the path to your .xlsx file: "))
protein_data <- read_excel(path=xlsx_path, skip=3) # skip=3 to omit the description rows

# Remove rows where the # column is a NA
protein_data <- protein_data[!is.na(protein_data$`#`), ]

# ------
# Prep and clean data: remove unneccessary columns, normalize the data. (run once)
# ------
  
# Find the column number of 'Taxonomy' (Assuming all of the numeric data is after 'Taxonomy' column)
taxonomy_col <- which(colnames(protein_data) == "Taxonomy")

# All columns after Taxonomy are numeric samples
sample_cols <- (taxonomy_col + 1):ncol(protein_data)

# Create a new data frame with normalized values
protein_data_normalized <- protein_data %>%
  mutate(across(all_of(sample_cols), ~ if_else(. == 0, 0, log2(.)))) # if value = 0, don't "log2 it", as that would result in a disruptive value (-Inf)

protein_data_normalized <- protein_data_normalized %>% dplyr::select(-c(`Molecular Weight`, `Taxonomy`, `Visible?`, `Starred?`,
                                                                 `Alternate ID`, `Protein Grouping Ambiguity`))


# Clean accession/entry names
protein_data_normalized <- protein_data_normalized %>%
  mutate(
    # Remove any " (+1)" or similar scaffold suffix
    AccessionNumberClean = str_remove(`Accession Number`, "\\s*\\(\\+.*\\)"),

    # Extract UniProtID if present (middle piece)
    UniProtID = str_extract(AccessionNumberClean, "(?<=\\|)[A-Z0-9]+(?=\\|)"),

    # Extract entry name (right-hand piece)
    EntryName = str_extract(AccessionNumberClean, "[A-Z0-9_]+(?=\\|?$)"),

    # Create Gene symbol (strip species suffix)
    GeneSymbol = str_remove(EntryName, "_[A-Z]+$")
  ) %>%
  # Keep only human proteins
  filter(str_detect(EntryName, "_HUMAN$")) %>%
  # Filter out rows with no UniProtID
  filter(!is.na(UniProtID)) %>%
  # Remove unwanted columns
  select(-`#`, -`Accession Number`)
```

# Run the fetch_go_for_protein function for each protein in parallel. Protein data with GO:terms that is normalized is in "protein_data_with_go" df
```{r}
# Set up parallel plan
plan(multisession, workers = parallel::detectCores() - 1)

# Function to safely wrap fetch_go_for_protein
safe_fetch_go <- function(uid) {
  tryCatch(
    fetch_go_for_protein(uid),
    error = function(e) {
      warning(sprintf("Failed for UniProtID %s: %s", uid, e$message))
      tibble(
        UniProtID = uid,
        goIds = list(character(0)),
        goNames = list(NA_character_),
        ontology = list(NA_character_)
      )
    }
  )
}

# UniProt IDs
uids <- protein_data_normalized$UniProtID

# Parallel fetch with progress bar
results_list <- future_map(uids, safe_fetch_go, .progress = TRUE)

# Combine results into a single data frame
go_annotations_df <- bind_rows(results_list)

# Merge back to original dataset safely
protein_data_with_go <- bind_cols(
  protein_data_normalized,
  go_annotations_df %>% select(-UniProtID)
)
```

### RUN ALL PREVIOUS CODE CELLS UP UNTIL THIS POINT. READ BELOW CAREFULLY
At this point, all functions should be loaded into your environment, and you should have a dataset named `protein_data_with_go` that has all of the proteins with their go_terms.

Running the next cell will allow you to filter proteins into two new datasets: `filtered_proteins` and `df_numeric`. `filtered_proteins` is the dataframe with all columns/data related to the proteins you've filtered for, and `df_numeric` is that same dataframe, except with only the numeric data kept and with the GeneSymbol column as rows.

# Run function + Prepare data analysis df as `df_numeric`.
```{r}
# `protein_data_with_go` is the dataset with go_terms (and already normalized numeric data)
filtered_proteins <- run_go_filter(protein_data_with_go)


### Make dataframe where row names are GeneSymbols and columns are proteins. Cell data is protein expressions.

# Change `df_numeric` to whatever you want to name the set (before the '<-')
# Change `filtered_proteins` to whatever (filtered) protein dataset you want to select from (after the '<-' and before the '%>%')
df_numeric <- filtered_proteins %>%
  select(where(is.numeric), GeneSymbol)

# Convert tibble to a data frame (since tibbles don't support rownames)
df_numeric <- as.data.frame(df_numeric)
# Remove any unwanted NA values
df_numeric$GeneSymbol[is.na(df_numeric$GeneSymbol) | df_numeric$GeneSymbol == ""] <- "Unknown"
df_numeric[is.na(df_numeric)] <- 0

# Make them unique by appending numbers (e.g., KRT1, KRT1.1, KRT1.2)
rownames(df_numeric) <- make.unique(df_numeric$GeneSymbol)
df_numeric$GeneSymbol <- NULL
```

### READ CAREFULLY contd.
After running this cell, you can perform further protein filtering using the `filter_numeric_protein_data` function *USE `df_numeric` FOR THIS*. You can also perform various data analysis functions (located in `data_analysis_functions.rmd`) on the `df_numeric` dataframe. Usage documents will be in `function_usage.txt`. Some examples are provided below.

```{r}
# Can name the new df anything you want (below is example)
TESTdf <- filter_numeric_protein_data(df_numeric, top_n_genes=50)
```

```{r}
# Assuming df_numeric is your dataframe with rownames = GeneSymbols
heatmap_plot <- plot_interactive_protein_heatmap(TESTdf,
                                                 cluster_rows = FALSE,
                                                 cluster_columns = FALSE,
                                                 tooltip_precision = 3)

# Show plot
heatmap_plot
```

```{r}
# Will prompt user
plot_protein_venn(TESTdf)
```